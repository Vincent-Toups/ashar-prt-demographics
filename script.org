#+TITLE: Notes for the BACPAC Data Portal Workshop
#+AUTHOR: Vincent Toups

* Introduction

Hi everyone. Thank you for making time to attend this small
workshop/hackathon to introduce the BACPAC Data
Portal.

Today we'll cover:

   1. Getting access to the data portal. (Although you hopefully did
      this before the workshop)
   2. Using the web based Data Portal to browse for assets and upload
      personal files.
   3. Starting and connecting to your virtual machines and doing a
      little analysis.
   4. Installing unusual software or libraries in your virtual
      machines
   5. Using Docker containers in the case that all else fails.

There will be a few points during the workshop where I'll as
participants to spend some time actually using the portal so that you
get go through some of the more technical parts of the process
yourself while I'm here to assist.

To give you all an excuse to do more than a little work on the portal,
we'll meet again in one week for people to share some interesting
visualizations of the Ashar data set.

* Gaining Access to the BACPAC Data Portal.

The key to accessing the data portal is the "Data Access and
Publication Request Form" which you or someone from your research
group will fill out. After you submitted your DAPR requests, you
should have been added to a project called "Workshop_April2022", which
will give you access to the data set we will be using in this project
(the data set associated with the Ashar et al 2021 paper "Effect of
Pain Reprocessing Therapy vs Placebo and Usual Care for Patients With
Chronic Back Pain A Randomized Clinical Trial").

The [[https://unc.az1.qualtrics.com/CP/File.php?F=F_eVy3GPRAKK2sTFY][form]] is available via Microsoft Teams and needs to be submitted
via [[https://teams.microsoft.com/l/channel/19%3A1f17988f3f9d47019b45e7221b449e14%40thread.skype/tab%3A%3Aaf358994-7635-4498-af88-bc767bd20348?groupId=6633d7f4-6063-419d-ba64-99e9b9e87e75&tenantId=58b3d54f-16c9-42d3-af08-1fcabd095666][Teams]].

You should all have filled this form out before this meeting and
already have data portal access and access to the Workshop_April2022
Project.

* The BACPAC Data Portal

Visit [[https://www.bacpacresearch.org][www.bacpacresearch.org]] and click log in. Here you log in with
whatever email address you used when making your DAPR request.

Then we're in.

#+CAPTION: The BACPAC Data Portal Welcome Page
#+NAME: welcome
[[./welcome.png]]

There is a lot going on with the data portal, so let's do a quick
run through.

The fundamental reason the data portal exists is to provide
researchers with a place to access data which cannot be readily
shared for confidentiality and privacy reasons. Instead of bringing
the data to your compute resources, the Data Portal lets you create
and work on compute resources which are next to the data.

In order to do that, each data portal account is associated with a
special profile. Once VMs are created on the Portal's web interface,
you can use that profile to log into the machines via your browser
and work from there.

#+CAPTION: Your profile page contains information necessary to log into your BACPAC Virtual Machines.
#+NAME: profile-page-ss-new
[[./profile-page-ss-new.png]]

* The Asset Browser

To facilitate asset sharing, the data portal provides an asset browser
which allows you to search for data available on the portal in a
variety of ways.

A variety of standard meta-data is available for each data set. In
addition, many data sets have custom meta-data fields which are
controlled by me and allow you to search (for instance) for any data
set which contains a particular column or column value (where
confidentially allows us to expose that information).

This meta-data search feature can be a little tricky to understand but
is pretty useful.

The technically savvy among us might want to think of a data-set's
meta-data as a JSON object with a set of Key/value pairs, where most
often the value of which is a list.

If you submit data to the Data Portal you may wish to let me know how
best to generate meta-data or to send the meta-data fields you'd like
to make searchable to me.
* Project Space

Each Data Access and Publication Request Form results in the creation
of a new project (project names are assigned by Cameron Gunn during
processing based on the information in the form) under the assumption
that each team implied in a new form (as opposed to a request for
modification) constitutes a new project.

These project spaces are a great place to host a _centralized_ git
repository, particularly because the VM firewall prevents access to
sites like github which might otherwise host git repositories.

* My Workspace

This is personal space. We'll see several uses for this space
throughout the workshop, but you can think of it as the "approved"
portal between your virtual machines and the outside world.

If you draft a paper inside your VM and want to download a PDF, then
you would put it in this space and Download it from the Data
Portal. If you want to upload an R library not available on CRAN, or a
set of SAS utilities that you carry around with you, you would upload
it to this space and it will be available within the VM.

* The Computing Console

Since this is a hackathon-type event lets just jump right into the
computing console.

#+CAPTION: The computing console.
#+NAME: compute-console
[[./compute-console.png]]

When you first log on you'll see that you have no machines of any
type associated with your account. I'm primarily a Linux users but
lets begin by starting a Windows VM (a small one). The plan here is
for us to start the VM, explore a data set, and then install some
custom software.

Click the "+" button next to the "Computing Console" title:

#+CAPTION: The "+" button allows you to create a new virtual machine.
#+NAME: the-plus-button
[[./the-plus-button.png]]


We have our choice of many virtual machines. Unless you have a
specific high performance computing task, its most cost effective
for BACPAC if you run a small VM. Let's do that now.

After waiting a little while our VM will be ready to go. Our login
process is a bit complicated, but let's go ahead and walk through
it.

We click the VM, copy the link from the connect button, paste it
into an incognito window, open our profile or VM page, and log in a
few times with our /vm/ password. Eventually we will find ourselves
looking at a Windows Desktop.

#+CAPTION: VMs use a different username and password which is presented here.
#+NAME: vm-user-and-password
[[./vm-user-and-password.png]]


#+CAPTION: No one knows.
#+NAME: dog
[[./dog.png]]

#+CAPTION: RDWeb, your gateway to the BACPAC Virtual Machines.
#+NAME: rd-web-opening-page
[[./rd-web-opening-page.png]]

We click "remote desktop" and then log in:

#+CAPTION: Log in with your special "profile" credentials.
#+NAME: log-in-1
[[./log-in-1.png]]

Click "show options"

#+CAPTION: Click "show options."
#+NAME: show-options
[[./show-options.png]]

The "Open" to open a pre-configured connection setup.
#+CAPTION: Click "open."
#+NAME: open-a-connection-configuration
[[./open-a-connection-configuration.png]]

And then select the right configuration for you virtual machine. Its
pretty straightforward: PRD-<OS>-<Number>-<Size>.

#+CAPTION: Opening a medium (M) windows (WIN) machine.
#+NAME: opening-a-medium-windows-machine
[[./opening-a-medium-windows-machine.png]]

After clicking "open" we can now click connect:

#+CAPTION: Clicking connect.
#+NAME: clicking-connect
[[./clicking-connect.png]]

And we have a few more hoops to jump through:

#+CAPTION: Click "connect."
#+NAME: accept-security-warning
[[./accept-security-warning.png]]

Enter your password again:

#+CAPTION: Enter your password again.
#+NAME: password-again
[[./password-again.png]]

Accept the certificate:

#+CAPTION: Accept the certificate.
#+NAME: accept-certificate
[[./accept-certificate.png]]

And you will be connected to your Virtual Machine's desktop.

** Tour of the VM

Regardless of the size of the VM you started, the setup of the Windows
VM will be similar. The most important element is the location of the
data. Let's navigate to C:/mnt/containers/ to see our personal,
project, and canonical data. For this tutorial we'll be working with
the Ashar data in the project space created for this workshop.

Things should more or less work as you expect in this VM. Note,
however, that most of the web is blocked to make accidentally
leaking confidential data more difficult.

There are exceptions to this rule meant to make life easier: CRAN
and PIP repositories are unlocked so you can install material from
them (assuming they don't require any other access to the internet).

For example, it isn't a standard part of the VM load out, but many
users enjoy using Jupyter notebooks to organize their work. We can
install Jupyter like this:

#+CAPTION: Using pip on Windows to install Jupyterlab.
#+NAME: pip-windows
[[./pip-windows.png]]

Or on a Linux machine:

#+CAPTION: Installing Jupyter Lab on Linux.
#+NAME: jupyter-on-linux
[[./jupyter-on-linux.png]]

#+CAPTION: Jupyter Lab up and running.
#+NAME: linux-tada
[[./linux-tada.png]]

** Data

The main point of the Data Portal is data analysis. The data portal
separates its data sets into three categories: Canonical Data which
is collected by and available to the entire consortium (this
includes publicly available data such as the Ashar data set we'll
use in the workshop today), Project Data (which only people who are
part of the project may access) and Personal Data which you may use
to move things in and out of the data portal.

On both linux and Windows these files are mounted in (more or less)
the same location:

/mnt/containers/

or

C:\mnt\containers\

Within these directories are the personal, project, and canonical
spaces.

If you upload data to your personal space, it will appear in the
folder under personal. You get the idea.

For today's workshop we'll be looking at the Ashar data set which is
available in a shared project folder we created explicitly for the
workshop:

#+begin_src fundamental
  C:\mnt\containters\project\Workshop_April2022/ashar_data
  # or
  /mnt/containers/project/Workshop_April2022/ashar_data
#+end_src

#+CAPTION: The location of the Ashar et al data set in the project space.
#+NAME: project-ashar-location
[[./project-ashar-location.png]]

** Doing something w/ the Data
* "Effect of Pain Reprocessing Therapy vs Placebo and Usual Care for Patients With Chronic Back Pain"

Everyone at the workshop should feel free to explore the data portal
with whatever data set they wish, but so that we can all have a common
baseline I'll be using data from the paper "Effect of Pain Reprocessing Therapy vs Placebo
and Usual Care for Patients With Chronic Back Pain" (Ashar et al, JAMA
Psychiatry, 2021).

Very briefly, this paper examines the efficacy of Pain
Recontextualization Therapy for chronic lower back pain (compared to
saline injections and standard of care).

Patients were split into three groups (Pain Recontextualization
Therapy (PRT), Saline Injection and standard of care) and tracked for
12 months. The results are very positive for PRT:

#+CAPTION: A pretty obvious success story.
#+NAME: effectiveness-of-prt-on-intensity
[[./effectiveness-of-prt-on-intensity.png]]

Let's take a deeper look at the data.

If we view the folder where our data is located:

#+CAPTION: The Ashar data set and associated meta-data.
#+NAME: ashar-dataset-location-windows
[[./ashar-dataset-location-windows.png]]

We can see that the data set comes with a codebook. We'll mostly be
working with the "clinical_outcomes.csv" data set here, and it turns
out that the information about this data set is in "Codebook
Additional notes.txt":

#+CAPTION: The clinical outcomes codebook.
#+NAME: codebook-ashar
[[./codebook-ashar.png]]

Let's use Windows and our newly installed Jupyter server to look at
our Ashar data set.

We'll be looking at the clinical outcomes data set from that
repository.

#+CAPTION: The first few rows and columns of the Ashar clinical outcomes data set.
#+NAME: ashar-clinical-outcomes-ss
[[./ashar-clinical-outcomes-ss.png]]


The simplest thing for us to do here is to load the data and make a
set of pairplots.

#+CAPTION: A subset of the pairplots from the Ashar clinical outcomes dataset.
#+NAME: ashar-clinical-outcomes
[[./ashar-clinical-outcomes.png]]

* Work Time

At this point I'd like to take a half hour to let participants log
into the Data Portal, build some VM's, log into them, and at least
open the data and look at it in their preferred environment. I'll be
available the entire time for questions. This is also a good time to
stretch your legs, make some tea, run a quick mile.

#+CAPTION: Try it out for yourself.
#+NAME: work-time
[[./work-time.png]]

* A Brief Aside about Ursala

#+CAPTION: Ursala may be used to instruct a computer to perform a task.
#+NAME: may-be-used
[[./may-be-used.png]]

Many years ago I was browsing Reddit (this was before reddit was
"cool"/"bad") when I encountered the following post:

You can imagine my confusion when I clicked through and saw someone
confidently espousing the value of their own home grown programming
language that looked like this:

#+CAPTION: Ursala - Thanks but no thanks.
#+NAME: thanks-but-no
[[./thanks-but-no.png]]

Ursala, I would later learn, is one of the many descendants of the
programming language [[https://en.wikipedia.org/wiki/APL_(programming_language)][APL]].

#+CAPTION: An APL Keyboard.
#+NAME: an-apl-keyboard
[[./an-apl-keyboard.png]]

Back when people still programmed in Perl, other people used to joke
that Perl looked like "line noise" - random characters you'd get if
you just send random fluctuations down a teletype terminal. Despite
the fact that Ursala looks a lot more like line noise than APL, I was
intrigued. In fact, I was already programming in Matlab, which, like
R and Numpy, are descendants of APL, and by pulling on the thread that
Ursala showed me, I eventually became interested in J.

And now I will pass that brain virus onto you.

The good ideas in J:

1. tacit programming - If an expression involves only functions (verbs
   in J) then that function "automagically" composes into a more
   complex function according to a few rules. This is a little mind
   bending but its sort of like "data flow" programming - you don't
   name things you operate on, just think about flow of data.
2. rank - verbs have "rank" (sort of like multidimensional matrices)
   that you can customize on the fly. This effects the way that verbs
   operate on the matrices: rank 0 verbs operate on the whole thing,
   rank 1 on the "1 cells" (eg, in a 1 dimensional array the elements,
   in a two dimensional array the rows, etc). Using rank you can
   eliminate almost all looping constructs.

The bad ideas in J:

1. everything else

* Installing External Software on your VMs

The VM's are totally locked down (with the exception of pip and CRAN
and a few other sites). So if you're a weirdo like me and you want to
program in J, you have to install this software on your own. The
general idea here is:

1. download the installer for your system
2. upload it to your VM
3. install the software there

But in practice making any specific piece of software work the way you
want can be a little tricky. Setting up J on the Windows VM is just
slightly non-trivial and so serves as a good use case.

The first step is to download J for Windows. If possible, you want to
download a "standalone" version of the software you need instead of an
installer. Its not uncommon for installers to want to talk to the
internet, and this is a non-starter.

If we visit [[https://jsoftware.com][JSoftware]] we can see what sort of installers we need.

J happens to have a zip "stand alone" type installer which we can grab
here:

#+CAPTION: Just a directory of files.
#+NAME: j-software-zip
[[./j-software-zip.png]]

We now just unpack this locally and follow the instructions. J is nice
in that you can install literally every package that it comes with in
a few minutes:

#+begin_src J
  load 'pacman'
  'install' jpkg '*'
  exit 0
#+end_src

So I've done this already on my CSCC Desktop (which runs windows) and
then copied it into my VM.

#+CAPTION: Uploading a zip of my J directories.
#+NAME: upload-j908-bundle
[[./upload-j908-bundle.png]]


Once I've got it into the VM, I can just start J and do some analysis:

#+CAPTION: Putting in error bars was more pain than I was willing to endure.
#+NAME: ashar-lineplot-from-j
[[./ashar-lineplot-from-j.png]]

Believe it or not, this is unusually comprehensible J.


* What (and why) is Docker?
Docker is a tool from the system's administrator's toolbox. It was
invented to solve at least one basic problem:

Software doesn't run in a vacuum. Any given program may depend on the
context it runs in (the operating system, libraries, environment
variables, network configuration) in non-trivial ways. Developers used
to solve this problem by either haphazardly, by manually configuring
machines for development and production for each user and deployment,
or by writing complicated scripts.

When virtualization became a thing, this process was made a little
easier: you could snapshot pristine VMs at just the point you needed
them and revert or copy snapshots around to smooth out these
processes.

But virtual machines are relatively heavy-weight. Docker is a
container platform which gives you some of the fleetness of simply
running a program and most of what you'd get from maintaining virtual
machine images. It also standardizes the process of setting up virtual
machines so that VM's can be shared as built images or just files
which describe the processes.

* Docker for BACPAC Machines

The utility of Docker containers for BACPAC researchers working on the
virtual machines is this:

if you can set up your workflow on a Linux machine using pretty much
arbitrary software, then you can build a Docker container on your
local machine, upload it the BACPAC Data Portal, and run that workflow
on a VM with access to the BACPAC Data.

We have tried to anticipate your software needs, but if we failed, you
can build a Docker container to get you where you need to go.  Please
let me know if you need any help getting a Docker container for a
particular use set up. It is part of what I am here for.

Docker is a large, relatively complex, ecosystem of software. We can
only scratch the surface here, but the surface is often all a Data
Scientist or Analyst needs to exploit Docker effectively.

* Brief Introduction to Docker and Dockerfiles

A Dockerfile is just a textual-representation of the steps a user
would perform in order to configure a particular operating system for
work.

Here is a simple example of a Docker file:

#+CAPTION: A very simple Dockerfile called scilab.Dockerfile
#+INCLUDE: "./scilab.Dockerfile" src Dockerfile

We can build an image based on this Dockerfile like this:

#+CAPTION: Building the Docker container.
#+begin_src sh
  docker build . -f scilab.Dockerfile -t scilab
#+end_src

And then we can run it:

#+CAPTION: Building the Docker container.
#+begin_src sh
  docker run -it scilab
#+end_src

And this will start an interactive scilab shell "inside" the
container.

Its important to realize that the container isolate you from the
operating system - by default, this scilab can't see any files outside
of the container.

If you have a very mature workflow, you may package source or
executables that perform an analysis directly into the container:

#+CAPTION: A very simple Dockerfile called scilab.Dockerfile
#+INCLUDE: "./scilab2.Dockerfile" src Dockerfile

#+CAPTION: Building the second Docker container.
#+begin_src sh
  docker build . -f scilab2.Dockerfile -t scilab2
  docker run -t scilab2
#+end_src

But it is much more common among Data Scientist to simply mount your
local directory as well as any data files in the container when you
run it.

#+CAPTION: Mounting our current directory /inside/ the container.
#+begin_src sh  
  docker run -v $(pwd):/home/rstudio/work -u rstudio -w /home/rstudio/work -t scilab
  --> exec("hello.sl") # note that this runs the version of hello.sl in our working directory.
#+end_src

If we were running our Docker container on our Virtual Machine, we
would also want to mount the container directory, like this:

#+CAPTION: Mounting our current directory /inside/ the container.
#+begin_src sh  
  docker run \
         -v /mnt/containers/project/Workshop_April2022/ashar_data:/mnt/containers/project/Workshop_April2022/ashar_data
         -v $(pwd):/home/rstudio/work\
         -u rstudio -w /home/rstudio/work -t scilab
  --> exec("hello.sl") # note that this runs the version of hello.sl in our working directory.
#+end_src

Speaking of which - how can we get our containers onto the VMs?

* How to get your Docker container onto the VM

In the near future we will enable a Docker registry accessible from
inside and outside of the Virtual Machines. When that happens you will
be able to push an image you have built locally to the registry and
pull it down inside your Virtual Machine.

In the meantime, however, the easiest solution is to export your
container after building it and upload it to your personal space. I'll
use a very small image as an example, since otherwise the upload
process can be challenging.

#+CAPTION: exporting and zipping up a Docker image.
#+begin_src sh
  docker pull hello-world
  docker save hello-world:latest | gzip > hello-world.tar.gz
#+end_src

#+CAPTION: Click the upload arrow in My Workspace.
#+NAME: upload-a-file-docker
[[./upload-a-file-docker.png]]

#+CAPTION: Select the hello-world.tar.gz image.
#+NAME: select-the-hello-world-image
[[./select-the-hello-world-image.png]]

On the virtual machine we simply write:

#+begin_src bash
  gunzip hello-world.tar.gz | docker image load
  docker run -t hello-world
#+end_src



